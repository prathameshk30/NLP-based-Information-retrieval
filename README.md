# NLP-based-Information-retrieval

 <image src="https://user-images.githubusercontent.com/89546195/232586030-b2473989-c50a-467d-ad70-47780161a430.png" width=150% height=150%>
 
 # Goal:-
 ## To design the best embedding for the given corpus of COVID- 19 text that can be used directly with any search emgine to fetch the relevant title & url to a given query.
 
# Scope of the Project
## The scope of the project is to understand ho w does the word vector or embedding generated from different Language Models perform for a given task. Understand how does word embeddings generated work for semantic relationship and syntetical relastionship. 
## Also explore the possibility of using a stack embedding for better semnatic search.

## Models explored:- Word2vec, BERT (Different alteration with the layers), LLM Model (OPEN-AI).
 
## Task done/ going:-
### 1) Train a Word 2 vec with different vector dimension , min_count to generate embeddings.
### 2) Generate BERT Embeddings with different configuration of the layers such as (last 4 (concat, mean, sum) ,last layer only, second last layer)
### 3) Generate Embedding using LLM such as OPEN AI.



