# NLP-based-Information-retrieval

 <img src="https://github.com/prathameshk30/NLP-based-Information-retrieval/assets/89546195/4e48c201-33ad-4988-87c6-026584f1ba5e" width=150% height=150%>

 
 # Goal:-
 #### To design the best embedding for the given corpus of COVID- 19 text that can be used directly with any search emgine to fetch the relevant title & url to a given query.
 
# Scope of the Project
#### The scope of the project is to understand ho w does the word vector or embedding generated from different Language Models perform for a given task. Understand how does word embeddings generated work for semantic relationship and syntetical relastionship. 
#### Also explore the possibility of using a stack embedding for better semnatic search.

# Models explored:- Word2vec, BERT (Different alteration with the layers), LLM Model (OPEN-AI).
 
### Task done/ going:-
#### 1) Train a Word 2 vec with different vector dimension , min_count to generate embeddings.
#### 2) Generate BERT Embeddings with different configuration of the layers such as (last 4 (concat, mean, sum) ,last layer only, second last layer)
#### 3) Generate Embedding using LLM such as OPEN AI.



